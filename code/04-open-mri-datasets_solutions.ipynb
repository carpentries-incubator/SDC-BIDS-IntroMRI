{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58da2fb",
   "metadata": {},
   "source": [
    "# Open MRI datasets\n",
    "\n",
    "---\n",
    "\n",
    "In this lesson, we will be using a subset of a publicly available dataset, **ds000030**, from [openneuro.org](https://openneuro.org/datasets/ds000030). All the datasets on OpenNeuro are already structured according to BIDS.\n",
    "\n",
    "## OpenNeuro\n",
    "\n",
    "- client-side BIDS validation\n",
    "- resumable uploads\n",
    "\n",
    "## Downloading data\n",
    "\n",
    "### DataLad\n",
    "\n",
    "Datalad is a great tool for \"versioning\" data. Downloading data using datalad has some advantages over downloading data via other ways:\n",
    "\n",
    "1. When you download the data, datalad is keeping track of exactly which version of the data you have. Meaning that if somebody updates/fixes that dataset later you can incorporate those fixes quickly.\n",
    "2. As datasets are getting bigger, we are getting to the point where all the data may not fit on your computer. Datalad first downloads the \"small\" data first (instead of the whole thing). So you can see what is there, plan your analysis, and only download the files you need to your local system.\n",
    "3. `datalad drop` let's you delete the files you are no longer using from your system - while holding on to the critical metadata that would allow you to report on the data, or re-download it to the same spot if you need it later.\n",
    "\n",
    "For more information about datalad - check out the [datalad handbook](http://handbook.datalad.org/en/latest/) or [this awesome tutorial video with rabbits!](https://www.youtube.com/watch?v=QsAqnP7TwyY).\n",
    "\n",
    "`DataLad` installs the data - which for a dataset means that we get the \"small\" data (i.e. the text files) and the download instructions for the larger files. We can now navigate the dataset like its a file system and plan our analysis.\n",
    "\n",
    "We'll switch to the terminal for this part.\n",
    "\n",
    "Navigate to the folder where you'd like to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../data && datalad install https://github.com/OpenNeuroDatasets/ds000030.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85020cbe",
   "metadata": {},
   "source": [
    "\"Getting\" the data is what actually downloads the larger files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d82048",
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad get ../data/ds000030/sub-10788"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38dde3c",
   "metadata": {},
   "source": [
    "\"Dropping\" the data deletes the larger datafile - while holding onto enough metadata that confidenty get it back if you need it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad drop ../data/ds000030/sub-10788"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1db119",
   "metadata": {},
   "source": [
    "#### if you need to deleted everything and restart...\n",
    "\n",
    "It happens. Removing the dataset entirely can be done with `datalad remove`. WARNING: Don't `datalad remove` during the workshop as you will need to redownload the dataset using the steps above.\n",
    "\n",
    "## Exploring a bids dataset\n",
    "\n",
    "Below is a tree diagram showing the folder structure of single MR session within ds000030."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b500e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree ../data/ds000030"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc85825",
   "metadata": {},
   "source": [
    "### the participants.tsv\n",
    "\n",
    "The `participants.tsv` file is meant to describe some demographic information on each participant within your study (eg. age, handedness, sex, etc.) Let's take a look at the `participants.tsv` file to see what's been included in this dataset.\n",
    "\n",
    "In order to load the data into Python, we'll need to import the `pandas` package. The `pandas` **dataframe** is Python's equivalent to an Excel spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bcd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52aa3e2",
   "metadata": {},
   "source": [
    "We'll use the `read_csv()` function. It requires us to specify the name of the file we want to import and the separator that is used to distinguish each column in our file (`\\t` since we're working with a `.tsv` file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62280025",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata = pd.read_csv('../data/ds000030/participants.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985e87a",
   "metadata": {},
   "source": [
    "In order to get a glimpse of our data, we'll use the `head()` function. By default, `head` prints the first 5 rows of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375654d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f192861",
   "metadata": {},
   "source": [
    "We can view any number of rows by specifying `n=?` as an argument within `head()`.  \n",
    "If we want to select particular rows within the dataframe, we can use the `loc[]` function and identify the rows we want based on their index label (the numbers in the left-most column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata.loc[[6, 10, 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f79097",
   "metadata": {},
   "source": [
    "**EXERCISE**: Select the first 5 rows of the dataframe using `loc[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fa9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata.loc[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560c3fa",
   "metadata": {},
   "source": [
    "**EXERCISE:** How many participants do we have in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed538d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad26543",
   "metadata": {},
   "source": [
    "There are 2 different methods of selecting columns in a dataframe:\n",
    "\n",
    "- participant_metadata[`'<column_name>'`] (this is similar to selecting a key in a Python dictionary)\n",
    "- participant_metadata.`<column_name>`\n",
    "\n",
    "Another way to see how many participants are in the study is to select the `participant_id` column and use the `count()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata['participant_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a08f0",
   "metadata": {},
   "source": [
    "**EXERCISE:** Which diagnosis groups are part of the study?  \n",
    "_Hint: use the_ `unique()` _function._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761e1a8",
   "metadata": {},
   "source": [
    "If we want to count the number of participants in each diagnosis group, we can use the `value_counts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2859e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3901f5",
   "metadata": {},
   "source": [
    "**EXERCISE:** How many males and females are in the study? How many are in each diagnosis group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0be83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata.groupby(['diagnosis', 'gender']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bdc85",
   "metadata": {},
   "source": [
    "When looking at the participant dataframe, we noticed that there is a column called `ghost_NoGhost`. We should look at the README file that comes with the dataset to find out more about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/ds000030/README"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb14bcd9",
   "metadata": {},
   "source": [
    "For this tutorial, we're just going to work with participants that are either CONTROL or SCHZ (`diagnosis`) and have both a T1w (`T1w == 1`) and rest (`rest == 1`) scan.\n",
    "\n",
    "**EXERCISE:** Filter `participant_metadata` so that only the above conditions are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_metadata = participant_metadata[(participant_metadata.diagnosis.isin(['CONTROL', 'SCHZ'])) &\n",
    "                                            (participant_metadata.T1w == 1) &\n",
    "                                            (participant_metadata.rest == 1)]\n",
    "participant_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455aa205",
   "metadata": {},
   "source": [
    "## Querying a BIDS dataset with pybids\n",
    "\n",
    "[pybids](https://bids-standard.github.io/pybids/) is a Python API for querying, summarizing and manipulating the BIDS folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids.layout import BIDSLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c366490",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(\"../data/ds000030\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5748598",
   "metadata": {},
   "source": [
    "Indexing a database can take a really long time, especially if you have several subjects, modalities, scan types, etc. `pybids` has an option to save the indexed results to a SQLite database. This database can then be re-used the next time you want to query the same database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13573c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.save(\"../data/ds000030/.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc894d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(\"../data/ds000030\", database_path = \"../data/ds000030/.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081b8f5",
   "metadata": {},
   "source": [
    "The pybids layout object lets you query your BIDS dataset according to a number of parameters by using a `get_*()` method.  \n",
    "We can get a list of the subjects we've downloaded from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb1a74f",
   "metadata": {},
   "source": "To get a list of all the files, just use `get()`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35986fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bf4de",
   "metadata": {},
   "source": [
    "There are many arguments we can use to filter down this list. Any BIDS-defined keyword can be passed on as a constraint. In `pybids`, these keywords are known as **entities**. For a complete list of possibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24fe8b",
   "metadata": {},
   "source": "For example, if we only want the file paths of all our resting state fMRI scans,"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get(datatype=\"func\", suffix=\"bold\", task=\"rest\", extension=[\".nii.gz\"], return_type=\"file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada0805",
   "metadata": {},
   "source": [
    "**EXERCISE**: Retrieve the file paths of any scan where the subject is '10292' or '50081' and the `RepetitionTime` is 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get(subject=\"10159\", RepetitionTime=2, return_type=\"file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b3bcd",
   "metadata": {},
   "source": [
    "Let's save the first file from our list of file paths to a variable and pull the metadata from its associated JSON file using the `get_metadata()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_file = layout.get(subject=\"10159\", RepetitionTime=2, return_type=\"file\")[0]\n",
    "layout.get_metadata(fmri_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c96aa6",
   "metadata": {},
   "source": "We can even collect the metadata for all our fmri scans into a list and convert this into a dataframe."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b839c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata_list = []\n",
    "all_fmri_files = layout.get(datatype=\"func\", suffix=\"bold\", return_type=\"file\", extension=[\".nii.gz\"])\n",
    "for fmri_file in all_fmri_files:\n",
    "    fmri_metadata = layout.get_metadata(fmri_file)\n",
    "    metadata_list.append(fmri_metadata)\n",
    "df = pd.DataFrame.from_records(metadata_list)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,../code//ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
