{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a NIfTI File\n",
    "\n",
    "teach you using Python and Jupyter notebooks. We'll start with a basic overview of how we can load, view, and play around with MR images using Python's neuroimaging libraries (<code>Nibabel</code>). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to NIfTI\n",
    "\n",
    "NIfTI is one of the most ubiquitous file formats for storing neuroimaging data. We'll cover a few details to get started working with them. If you're interested in learning more about NIfTI images, we highly recommend [this blog post about the NIfTI format](http://brainder.org/2012/09/23/the-nifti-file-format/).\n",
    "\n",
    "### Reading NIfTI Images\n",
    "\n",
    "[NiBabel](http://nipy.org/nibabel/) is a Python package for reading and writing neuroimaging data. To learn more about how NiBabel handles NIfTIs, check out the [Working with NIfTI images](http://nipy.org/nibabel/nifti_images.html) page of the NiBabel documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, use the `load()` function to create a NiBabel image object from a NIfTI file. We'll load in a T1w image from the dataset we'll be using for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/mjoseph/.pyenv/versions/carpentry_venv/lib/python3.7/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-abcdd3ce3fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/mjoseph/.pyenv/versions/carpentry_venv/lib/python3.7/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or no access: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz'"
     ]
    }
   ],
   "source": [
    "t1_img = nib.load('../data/ds000030/sub-10171/anat/sub-10171_T1w.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NiBabel image object contains several components called **attributes** in Python's terminology. To see all of these attributes, type `t1_img.` and <kbd>Tab</kbd>.  \n",
    "There are three main attributes that we'll discuss today:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [Header](http://nipy.org/nibabel/nibabel_images.html#the-image-header): contains metadata about the image, such as image dimensions, data type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr = t1_img.header\n",
    "print(t1_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NiBabel image header is a Python **dictionary**. Dictionaries are containers that hold pairs of objects - keys and values. Let's take a look at all of the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the value stored by a given key by typing:\n",
    "\n",
    "```python\n",
    "t1_hdr['<key_name>']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Extract the value of <code>pixdim</code> from <code>t1_hdr</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr['pixdim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data\n",
    "The data is a multidimensional array representing the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data = t1_img.get_fdata()\n",
    "t1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in the array corresponds to an intensity value. The range of values typically goes from 0 (black) to 255 (white)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some basic properties of the array.  \n",
    "The `type()` function will only tell you that a variable is a NumPy array. It won’t tell you the type of data inside of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the NumPy array’s elements are floating-point numbers.   \n",
    "The data type of an image controls the range of possible intensities. As the number of possible values increases, the amount of space the image takes up in memory also increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> How can we see the number of dimensions in the <code>t1_data</code> array? What about the array's shape? Once again, all of the attributes of the array can be seen by typing <code>t1_data.</code> and <kbd>Tab</kbd>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the data always has at least 3 dimensions (X, Y, and Z) and sometimes a 4th, T (time).  \n",
    "This T1w image has 3 dimensions. This means that the brain was scanned in 176 slices with a resolution of 256 x 256 voxels per slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/images/mri_slices.jpg\" alt=\"Drawing\" align=\"middle\" width=\"300px\"/>\n",
    "\n",
    "Sourced from: Tariq, Humera & Burney, S.M.Aqil. (2014). Brain MRI literature review for interdisciplinary studies. Journal of biomedical graphics and computing. 4. 41-53. 10.5430/jbgc.v4n4p41. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. [Affine](http://nipy.org/nibabel/coordinate_systems.html): tells the position of the image array data in a *reference space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we identify the location of an object in space? Coordinate systems! The most common coordinate system in neuroimaging is called *RAS* (right (X), anterior (Y), superior (Z)). A coordinate of (2, -10, 5) refers to a point in space 2 mm to the right, 10 mm to the back and 5 mm above. The affine array helps us identify a real location for each voxel in our image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/images/coordinate_systems.png\" alt=\"Drawing\" align=\"middle\" width=\"300px\"/>\n",
    "\n",
    "Sourced from: https://www.slicer.org/wiki/Coordinate_systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_affine = t1_img.affine\n",
    "t1_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Image Data\n",
    "\n",
    "#### Slicing\n",
    "\n",
    "n-dimensional images are just stacks of numpy arrays.  Each value in the array is assigned to an x, y or z coordinate.  \n",
    "<img src=\"../static/images/numpy_arrays.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>\n",
    "\n",
    "You'll recall our example T1w image is a 3D image with dimensions $176 \\times 256 \\times 256$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing does exactly what it seems to imply. Giving our 3D volume, we pull out a 2D slice of our data. Here's an example of slicing from left to right (**sagittal slicing**):\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_%28ANIMATED%29.gif\"/>\n",
    "\n",
    "This gif is a series of 2D images or **slices** moving from left to right. We'll now look into how we can pull slices from our 3D image\n",
    "\n",
    "***\n",
    "Sourced from: https://en.wikipedia.org/wiki/Neuroimaging#/media/File:Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_(ANIMATED).gif\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have two ways of working with neuroimaging data. \n",
    "\n",
    "\n",
    "1. We have the actual <code>t1_img</code> we loaded using <code>nibabel</code>\n",
    "2. We have the array we pulled from <code>t1_img</code> in the form of <code>t1_data</code>\n",
    "\n",
    "\n",
    "For each of these representations of our data we can pull \"slices\" using different methods.\n",
    "\n",
    "\n",
    "First we'll work with the array in the form of <code>t1_img</code>. Since this is a <code>numpy</code> array, we can use the same method as we'd use when dealing with 3D arrays in Python (R and MATLAB are very similar here!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the 10th \"sagittal slice\"\n",
    "sagittal_slice = t1_data[10,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the following structure: \n",
    "\n",
    "1. We can **index** an array using the array followed by square brackets as follows t1_data[x,y,z]\n",
    "\n",
    "With our data:\n",
    "- <code>x</code> is the left to right index\n",
    "- <code>y</code> is the back to front index\n",
    "- <code>z</code> is the bottom to top index\n",
    "\n",
    "\n",
    "So here we're selecting the 10th slice going from left to right (there are 176 slices going from left to right!)\n",
    "\n",
    "The <code>:</code>, indicates that we want to grab *everything*. \n",
    "\n",
    "In plain english we want to:\n",
    "\n",
    "**Move 10 spots from the left, then grab a full 2D picture here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Now try selecting the 70th slice from the back (this is called a **coronal slice**).\n",
    "It helps to think of this as follows:\n",
    "\n",
    "Move 70 spots from the back, then grab the full 2D picture here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coronal_slice = t1_data[:,70,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally try grabbing a **axial slice**, specifically the 126th slice from the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_slice = t1_data[:,:,126]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier we can also slice using <code>t1_img</code>, which we loaded through <code>nibabel</code>. It's sometimes nicer to work with this since we don't have to deal with arrays directly like we did with <code>t1_data</code>. \n",
    "\n",
    "Slicing with <code>t1_img</code> is just as straightforward and involves using <code>t1_img.slicer[x,y,z]</code>, but with a single caveat which we'll demonstrate here using the 10th slice from the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagittal_slice = t1_img.slicer[10:11,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference? Here we have to format a sagittal slice as follows:\n",
    "\n",
    "<code>t1_img.slicer[ (slice) :  (slice# +1) ,:,:]</code>\n",
    "\n",
    "This is just a result of how <code>slicer</code> is programmed, but everything else remains the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Use <code>t1_img.slicer</code> to select the:\n",
    "\n",
    "1. 70th coronal slice from the back\n",
    "2. 126th axial slice from the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coronal slice\n",
    "coronal_slice = t1_img.slicer[:,70:71,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Axial Slice\n",
    "axial_slice = t1_img.slicer[:,:,126:127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been slicing and dicing brain images but we have no idea what they look like! In the next section we'll show you how you can visualize brain slices using <code>nibabel</code>!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing\n",
    "If we wanted to get a quick view of our data, Nibabel provides this functionality through a method called <code>orthoview()</code>. Here's how it looks in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing NIfTI Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the mask we just created to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask = nib.Nifti1Image(mask_apply, t1_affine, t1_hdr)\n",
    "img_mask.to_filename('../data/test_mask.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_venv",
   "language": "python",
   "name": "fmri_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
